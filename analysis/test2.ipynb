{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import statistics\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveformProcessor:\n",
    "    \"\"\"\n",
    "    Base class for storing and processing waveform data from different boards\n",
    "    \"\"\"\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name or \"Unnamed\"\n",
    "        self.channels = {}  # Main data structure\n",
    "\n",
    "    def get_available_channels(self):\n",
    "        \"\"\"\n",
    "        Get the channels that have data stored in the dictionary\n",
    "        \"\"\"\n",
    "        return sorted(list(self.channels.keys()))\n",
    "\n",
    "    def get_channel_waveform(self, waveform_type='singles', channel=None, trace_index=0):\n",
    "        \"\"\"\n",
    "        Get a specific waveform of a channel\n",
    "        \n",
    "        Args:\n",
    "            waveform_type (str): 'singles' or 'averages'\n",
    "            channel (int): Channel number\n",
    "            trace_index (int): Index of the trace to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: The requested waveform dataframe\n",
    "        \"\"\"\n",
    "        if channel not in self.channels:\n",
    "            raise ValueError(f\"Channel {channel} not found\")  \n",
    "\n",
    "        if waveform_type not in self.channels[channel]:\n",
    "            raise ValueError(f\"Channel {channel} does not have {waveform_type} data\")\n",
    "\n",
    "        if trace_index not in self.channels[channel][waveform_type]:\n",
    "            raise ValueError(f\"Channel {channel} does not have trace {trace_index} in {waveform_type} data. There are {len(self.channels[channel][waveform_type].keys())} traces available.\")\n",
    "\n",
    "        return self.channels[channel][waveform_type][trace_index]\n",
    "\n",
    "    def get_pedestal(self, data, baseline_start_pct=0, baseline_end_pct=0.2):\n",
    "        \"\"\"\n",
    "        Calculate the pedestal (baseline) of a waveform within a specified range of the data\n",
    "        \"\"\"\n",
    "        start_idx = int(len(data) * baseline_start_pct)\n",
    "        end_idx = int(len(data) * baseline_end_pct)\n",
    "        return np.mean(data[start_idx:end_idx+1])\n",
    "\n",
    "    def getPeakIndex(self, data, baseline_start_pct=0, baseline_end_pct=0.2, threshold=0.1):\n",
    "        \"\"\"\n",
    "        Get the index of the peak value in a waveform above a specified threshold\n",
    "        \"\"\"\n",
    "        peak_value = 0\n",
    "        peak_index = 0\n",
    "        threshold_index = 0\n",
    "        crossed_threshold = False\n",
    "        counter = 0\n",
    "        pedestal = self.get_pedestal(data, baseline_start_pct, baseline_end_pct)\n",
    "        for i in range(len(data)):\n",
    "            if not crossed_threshold and data[i]-pedestal>threshold:\n",
    "                crossed_threshold = True\n",
    "                threshold_index = i\n",
    "            if crossed_threshold and data[i]>peak_value:\n",
    "                peak_value = data[i]\n",
    "                peak_index = i\n",
    "            elif crossed_threshold and data[i]<=peak_value:\n",
    "                counter += 1\n",
    "            if crossed_threshold and counter>1:\n",
    "                break\n",
    "        return peak_index, threshold_index\n",
    "    \n",
    "    def calculate_rise_time(self, channel, waveform_type='singles', trace_index=0, baseline_start_pct=0, baseline_end_pct=0.2, threshold=0.01, low_pct=0.1, high_pct=0.9):\n",
    "        \"\"\"\n",
    "        Calculate rise time for a given channel.\n",
    "        \"\"\"\n",
    "        df = self.get_channel_waveform(waveform_type, channel, trace_index)\n",
    "        time = df[\"time\"].values * 1e9 # Convert to ns\n",
    "        signal = df[\"output\"].values * 1e3 # Convert to mV\n",
    "\n",
    "        pedestal = self.get_pedestal(signal, baseline_start_pct, baseline_end_pct)\n",
    "        peak_index,threshold_index = self.getPeakIndex(signal, baseline_start_pct, baseline_end_pct, threshold)\n",
    "        amplitude = signal[peak_index] - pedestal\n",
    "        low_threshold = amplitude * low_pct - pedestal \n",
    "        high_threshold = amplitude * high_pct - pedestal\n",
    "\n",
    "        interp_func = interp1d(time, signal, kind='linear') \n",
    "        interp_time = np.linspace(time[0], time[-1], num=10000)\n",
    "        interp_signal = interp_func(interp_time)\n",
    "        signal_above_low = interp_signal >= low_threshold\n",
    "        signal_above_high = interp_signal >= high_threshold\n",
    "        if np.any(signal_above_low):\n",
    "            t_low_index = np.argmax(signal_above_low)\n",
    "            t_low = interp_time[t_low_index]\n",
    "        else:\n",
    "            t_low = np.nan\n",
    "\n",
    "        if np.any(signal_above_high):\n",
    "            t_high_index = np.argmax(signal_above_high)\n",
    "            t_high = interp_time[t_high_index]\n",
    "        else:\n",
    "            t_high = np.nan\n",
    "\n",
    "        rise_time = t_high - t_low\n",
    "\n",
    "        if 'analysis' not in self.channels[channel]:\n",
    "            self.channels[channel]['analysis'] = {}\n",
    "\n",
    "        self.channels[channel]['analysis']['rise_time'] = {\n",
    "            \"value\": rise_time,\n",
    "            \"source\": waveform_type,\n",
    "            \"trace_index\": trace_index,\n",
    "            \"t_low\": t_low,\n",
    "            \"t_high\": t_high,\n",
    "            \"low_threshold\": low_threshold,\n",
    "            \"high_threshold\": high_threshold,\n",
    "            \"amplitude\": amplitude,\n",
    "            \"pedestal\": pedestal\n",
    "        }\n",
    "        return rise_time, t_low, t_high\n",
    "    \n",
    "    def calculate_all_rise_times(self, waveform_type='singles', trace_index=0,\n",
    "                               baseline_start_pct=0, baseline_end_pct=0.2, \n",
    "                               threshold=0.01, low_pct=0.1, high_pct=0.9):\n",
    "        \"\"\"\n",
    "        Calculate rise times for all loaded channels.\n",
    "        \n",
    "        Args:\n",
    "            waveform_type (str): 'singles' or 'averages'\n",
    "            trace_index (int): Index of the trace to use\n",
    "            baseline_start_pct (float): Start point for baseline calculation\n",
    "            baseline_end_pct (float): End point for baseline calculation\n",
    "            threshold (float): Threshold for peak detection\n",
    "            low_pct (float): Lower threshold percentage (0-1)\n",
    "            high_pct (float): Upper threshold percentage (0-1)\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary of rise times by channel\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for channel in self.channels:\n",
    "            try:\n",
    "                if waveform_type in self.channels[channel] and trace_index in self.channels[channel][waveform_type]:\n",
    "                    rt, t_low, t_high = self.calculate_rise_time(\n",
    "                        channel, waveform_type, trace_index,\n",
    "                        baseline_start_pct, baseline_end_pct, \n",
    "                        threshold, low_pct, high_pct\n",
    "                    )\n",
    "                    results[channel] = rt\n",
    "                    print(f\"Channel {channel}: Rise time = {rt*1e9:.2f} ns\")\n",
    "                else:\n",
    "                    print(f\"Channel {channel}: No {waveform_type} data at index {trace_index}\")\n",
    "                    results[channel] = np.nan\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing channel {channel}: {e}\")\n",
    "                results[channel] = np.nan\n",
    "                \n",
    "        return results\n",
    "    \n",
    "    def calculate_delays(self, waveform_type='averages', trace_index=0, reference_channel=None):\n",
    "        \"\"\"\n",
    "        Calculate delays relative to reference channel.\n",
    "        \n",
    "        Args:\n",
    "            waveform_type (str): 'singles' or 'averages'\n",
    "            trace_index (int): Index of the trace to use\n",
    "            reference_channel (int, optional): Channel to use as reference. If None, uses channel with minimum rise time.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary of delays by channel in picoseconds\n",
    "        \"\"\"\n",
    "        # First ensure we have rise time data\n",
    "        channels_with_rt = {}\n",
    "        for ch in self.channels:\n",
    "            if ('analysis' in self.channels[ch] and \n",
    "                'rise_time' in self.channels[ch]['analysis']):\n",
    "                channels_with_rt[ch] = self.channels[ch]['analysis']['rise_time']\n",
    "        \n",
    "        if not channels_with_rt:\n",
    "            print(\"No rise time measurements found. Calculating...\")\n",
    "            self.calculate_all_rise_times(waveform_type, trace_index)\n",
    "            \n",
    "            # Check again\n",
    "            channels_with_rt = {}\n",
    "            for ch in self.channels:\n",
    "                if ('analysis' in self.channels[ch] and \n",
    "                    'rise_time' in self.channels[ch]['analysis']):\n",
    "                    channels_with_rt[ch] = self.channels[ch]['analysis']['rise_time']\n",
    "            \n",
    "            if not channels_with_rt:\n",
    "                raise ValueError(\"Failed to calculate rise times. Cannot calculate delays.\")\n",
    "        \n",
    "        # Find reference channel if not specified\n",
    "        if reference_channel is None:\n",
    "            min_rt = float('inf')\n",
    "            for ch, rt_data in channels_with_rt.items():\n",
    "                if not np.isnan(rt_data['value']) and rt_data['value'] < min_rt:\n",
    "                    min_rt = rt_data['value']\n",
    "                    reference_channel = ch\n",
    "            \n",
    "            if reference_channel is None:\n",
    "                raise ValueError(\"No valid rise time found for any channel.\")\n",
    "        \n",
    "        if reference_channel not in channels_with_rt:\n",
    "            raise ValueError(f\"Reference channel {reference_channel} has no rise time data\")\n",
    "        \n",
    "        # Get reference t_low time\n",
    "        ref_t_low = channels_with_rt[reference_channel]['t_low']\n",
    "        \n",
    "        # Calculate delays for all channels\n",
    "        delays = {}\n",
    "        for ch in self.channels:\n",
    "            if ('analysis' in self.channels[ch] and \n",
    "                'rise_time' in self.channels[ch]['analysis'] and \n",
    "                not np.isnan(self.channels[ch]['analysis']['rise_time']['t_low'])):\n",
    "                \n",
    "                # Calculate delay in picoseconds\n",
    "                ch_t_low = self.channels[ch]['analysis']['rise_time']['t_low']\n",
    "                delay_ps = (ch_t_low - ref_t_low) * 1e12\n",
    "                \n",
    "                # Store result\n",
    "                if 'analysis' not in self.channels[ch]:\n",
    "                    self.channels[ch]['analysis'] = {}\n",
    "                \n",
    "                self.channels[ch]['analysis']['delay'] = {\n",
    "                    'value': delay_ps,\n",
    "                    'reference_channel': reference_channel,\n",
    "                    'source': waveform_type,\n",
    "                    'trace_index': trace_index\n",
    "                }\n",
    "                \n",
    "                delays[ch] = delay_ps\n",
    "            else:\n",
    "                delays[ch] = np.nan\n",
    "        \n",
    "        return delays\n",
    "    \n",
    "    def calculate_gains(self, waveform_type='averages', trace_index=0):\n",
    "        \"\"\"\n",
    "        Calculate gains for all channels by comparing input and output amplitudes.\n",
    "        \n",
    "        Args:\n",
    "            waveform_type (str): 'singles' or 'averages'\n",
    "            trace_index (int): Index of the trace to use\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary of gains by channel\n",
    "        \"\"\"\n",
    "        gains = {}\n",
    "        \n",
    "        for ch in self.channels:\n",
    "            try:\n",
    "                if (waveform_type in self.channels[ch] and \n",
    "                    trace_index in self.channels[ch][waveform_type]):\n",
    "                    \n",
    "                    df = self.get_channel_waveform(waveform_type, ch, trace_index)\n",
    "                    \n",
    "                    # Check if we have both input and output columns\n",
    "                    if \"input\" in df.columns and (\"output\" in df.columns or \"amplitude\" in df.columns):\n",
    "                        # Get input and output signals\n",
    "                        input_signal = df[\"input\"].values\n",
    "                        output_signal = df[\"amplitude\"].values if \"amplitude\" in df.columns else df[\"output\"].values\n",
    "                        \n",
    "                        # Calculate pedestals\n",
    "                        input_pedestal = self.get_pedestal(input_signal)\n",
    "                        output_pedestal = self.get_pedestal(output_signal)\n",
    "                        \n",
    "                        # Adjust signals\n",
    "                        input_adj = input_signal - input_pedestal\n",
    "                        output_adj = output_signal - output_pedestal\n",
    "                        \n",
    "                        # Find peaks\n",
    "                        input_peak = np.max(np.abs(input_adj))\n",
    "                        output_peak = np.max(np.abs(output_adj))\n",
    "                        \n",
    "                        # Calculate gain (output/input)\n",
    "                        if input_peak != 0:\n",
    "                            gain = output_peak / input_peak\n",
    "                        else:\n",
    "                            gain = np.nan\n",
    "                            \n",
    "                        # Store in channel's analysis\n",
    "                        if 'analysis' not in self.channels[ch]:\n",
    "                            self.channels[ch]['analysis'] = {}\n",
    "                            \n",
    "                        self.channels[ch]['analysis']['gain'] = {\n",
    "                            'value': gain,\n",
    "                            'input_peak': input_peak,\n",
    "                            'output_peak': output_peak,\n",
    "                            'source': waveform_type,\n",
    "                            'trace_index': trace_index\n",
    "                        }\n",
    "                        \n",
    "                        gains[ch] = gain\n",
    "                        print(f\"Channel {ch}: Gain = {gain:.4f}\")\n",
    "                    else:\n",
    "                        print(f\"Channel {ch} missing input or output data\")\n",
    "                        gains[ch] = np.nan\n",
    "                else:\n",
    "                    print(f\"No {waveform_type} data for channel {ch} at index {trace_index}\")\n",
    "                    gains[ch] = np.nan\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating gain for channel {ch}: {e}\")\n",
    "                gains[ch] = np.nan\n",
    "                \n",
    "        return gains\n",
    "    \n",
    "    def plot_waveform(self, channel, waveform_type='singles', trace_index=0, show_thresholds=True):\n",
    "        \"\"\"\n",
    "        Plot a waveform for a specific channel.\n",
    "        \n",
    "        Args:\n",
    "            channel (int): Channel identifier\n",
    "            waveform_type (str): 'singles' or 'averages'\n",
    "            trace_index (int): Index of the trace to plot\n",
    "            show_thresholds (bool): Whether to show threshold markers\n",
    "            \n",
    "        Returns:\n",
    "            matplotlib.figure.Figure: The figure object\n",
    "        \"\"\"\n",
    "        df = self.get_channel_waveform(waveform_type, channel, trace_index)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        # Plot the waveform\n",
    "        time_ns = df[\"time\"].values * 1e9  # Convert to nanoseconds\n",
    "        if \"amplitude\" in df.columns:\n",
    "            signal = df[\"amplitude\"].values\n",
    "        elif \"output\" in df.columns:\n",
    "            signal = df[\"output\"].values\n",
    "        else:\n",
    "            raise ValueError(f\"No amplitude or output column found in {waveform_type} data for channel {channel}\")\n",
    "        \n",
    "        # Get pedestal if available or calculate it\n",
    "        if ('analysis' in self.channels[channel] and \n",
    "            'rise_time' in self.channels[channel]['analysis']):\n",
    "            pedestal = self.channels[channel]['analysis']['rise_time']['pedestal']\n",
    "        else:\n",
    "            pedestal = self.get_pedestal(signal)\n",
    "            \n",
    "        signal_adj = signal - pedestal\n",
    "            \n",
    "        ax.plot(time_ns, signal_adj, label=f\"{self.name} Ch{channel} ({waveform_type})\")\n",
    "        \n",
    "        # Show threshold markers if requested and available\n",
    "        if (show_thresholds and 'analysis' in self.channels[channel] and \n",
    "            'rise_time' in self.channels[channel]['analysis']):\n",
    "            \n",
    "            rt_data = self.channels[channel]['analysis']['rise_time']\n",
    "            t_low_ns = rt_data['t_low']\n",
    "            t_high_ns = rt_data['t_high']\n",
    "            low_threshold = rt_data['low_threshold'] - pedestal  # Adjust for plotting\n",
    "            high_threshold = rt_data['high_threshold'] - pedestal\n",
    "            \n",
    "            # Add vertical lines at threshold crossings\n",
    "            ax.axvline(x=t_low_ns, color='green', linestyle='--', \n",
    "                      label=f'tLow = {t_low_ns:.2f} ns')\n",
    "            ax.axvline(x=t_high_ns, color='red', linestyle='--', \n",
    "                      label=f'tHigh = {t_high_ns:.2f} ns')\n",
    "            \n",
    "            # Add horizontal lines at threshold levels\n",
    "            ax.axhline(y=low_threshold, color='green', linestyle=':')\n",
    "            ax.axhline(y=high_threshold, color='red', linestyle=':')\n",
    "            \n",
    "            # Add rise time text\n",
    "            rise_time_ns = rt_data['value']\n",
    "            ax.text(0.7, 0.9, f\"Rise Time: {rise_time_ns:.2f} ns\", \n",
    "                   transform=ax.transAxes, fontsize=12, \n",
    "                   bbox=dict(facecolor='white', alpha=0.7))\n",
    "            \n",
    "        ax.set_xlabel(\"Time (ns)\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.set_title(f\"{self.name} Channel {channel} Waveform ({waveform_type})\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_delays(self, highlight_extremes=True):\n",
    "        \"\"\"\n",
    "        Plot channel delays as a bar chart.\n",
    "        \n",
    "        Args:\n",
    "            highlight_extremes (bool): Whether to highlight min/max delays\n",
    "            \n",
    "        Returns:\n",
    "            matplotlib.figure.Figure: The figure object\n",
    "        \"\"\"\n",
    "        # Get all channels with delay measurements\n",
    "        channels_with_delays = {}\n",
    "        for ch in self.channels:\n",
    "            if ('analysis' in self.channels[ch] and \n",
    "                'delay' in self.channels[ch]['analysis']):\n",
    "                channels_with_delays[ch] = self.channels[ch]['analysis']['delay']['value']\n",
    "        \n",
    "        if not channels_with_delays:\n",
    "            raise ValueError(\"No delay measurements found. Run calculate_delays first.\")\n",
    "            \n",
    "        # Create labels and delay array\n",
    "        ch_nums = sorted(list(channels_with_delays.keys()))\n",
    "        labels = [f\"CH{ch}\" for ch in ch_nums]\n",
    "        delays = [channels_with_delays[ch] for ch in ch_nums]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        # Create bar plot\n",
    "        bars = ax.bar(labels, delays)\n",
    "        \n",
    "        if highlight_extremes:\n",
    "            # Find min (excluding 0 which is reference)\n",
    "            non_zero_delays = [d for d in delays if d != 0]\n",
    "            if non_zero_delays:\n",
    "                min_idx = delays.index(min(non_zero_delays))\n",
    "                max_idx = delays.index(max(delays))\n",
    "                \n",
    "                # Find second lowest if needed\n",
    "                if min_idx == delays.index(0):  # If the minimum is the reference channel (0 delay)\n",
    "                    # Make a copy and replace the lowest with infinity\n",
    "                    temp_values = delays.copy()\n",
    "                    temp_values[min_idx] = float('inf')\n",
    "                    min_idx = temp_values.index(min(temp_values))\n",
    "                \n",
    "                # Highlight min/max bars\n",
    "                bars[min_idx].set_color('lightgreen')\n",
    "                bars[max_idx].set_color('tomato')\n",
    "                \n",
    "                # Add value labels\n",
    "                ax.text(min_idx, delays[min_idx]+20, f\"{delays[min_idx]:.0f}\", \n",
    "                       ha='center', rotation=90)\n",
    "                ax.text(max_idx, delays[max_idx]+20, f\"{delays[max_idx]:.0f}\", \n",
    "                       ha='center', rotation=90)\n",
    "        \n",
    "        # Calculate standard deviation\n",
    "        std_dev = np.std([d for d in delays if not np.isnan(d) and d != 0])\n",
    "        \n",
    "        ax.set_xlabel(\"Channel\")\n",
    "        ax.set_ylabel(\"Delay Relative to Reference Channel [ps]\")\n",
    "        ax.set_title(f\"{self.name} Unity Path Relative Channel Delays\")\n",
    "        ax.set_ylim(0, max(delays) * 1.2)  # Add 20% margin\n",
    "        ax.legend([f'$\\\\sigma= {std_dev:.2f}$'])\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_multiple_traces(self, channel, waveform_type='singles', max_traces=5, ax=None):\n",
    "        \"\"\"\n",
    "        Plot multiple traces for a channel on the same axes.\n",
    "        \n",
    "        Args:\n",
    "            channel (int): Channel number\n",
    "            waveform_type (str): 'singles' or 'averages'\n",
    "            max_traces (int): Maximum number of traces to plot\n",
    "            ax (matplotlib.axes.Axes, optional): Axes to plot on\n",
    "            \n",
    "        Returns:\n",
    "            matplotlib.axes.Axes: The plot axes\n",
    "        \"\"\"\n",
    "        if channel not in self.channels or waveform_type not in self.channels[channel]:\n",
    "            raise ValueError(f\"No {waveform_type} data found for channel {channel}\")\n",
    "            \n",
    "        traces = self.channels[channel][waveform_type]\n",
    "        if not traces:\n",
    "            raise ValueError(f\"No traces found for channel {channel} in {wf_type}\")\n",
    "            \n",
    "        # Create or use provided axes\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            \n",
    "        # Limit number of traces to prevent overcrowding\n",
    "        trace_nums = sorted(list(traces.keys()))[:max_traces]\n",
    "        \n",
    "        for i, trace_num in enumerate(trace_nums):\n",
    "            df = traces[trace_num]\n",
    "            if \"output\" in df.columns:\n",
    "                label = f\"Trace {trace_num}\"\n",
    "                ax.plot(df[\"time\"] * 1e9, df[\"output\"], label=label, alpha=0.7)\n",
    "            elif \"amplitude\" in df.columns:\n",
    "                label = f\"Trace {trace_num}\"\n",
    "                ax.plot(df[\"time\"] * 1e9, df[\"amplitude\"], label=label, alpha=0.7)\n",
    "            \n",
    "        ax.set_xlabel(\"Time (ns)\")\n",
    "        ax.set_ylabel(\"Output\")\n",
    "        ax.set_title(f\"{self.name} Channel {channel} - {waveform_type.capitalize()} Traces\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        \n",
    "        return ax\n",
    "    \n",
    "    def load_data(self, file_pattern=None):\n",
    "        \"\"\"\n",
    "        Load data files. To be implemented by subclasses.\n",
    "        \n",
    "        Args:\n",
    "            file_pattern (str): Pattern to match files\n",
    "            \n",
    "        Returns:\n",
    "            int: Number of channels loaded\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement load_data()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CASB1Processor(WaveformProcessor):\n",
    "    \"\"\"Processor for CASB1 board data.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"CASB1\")\n",
    "    \n",
    "    def load_singles(self, path=\"../data/casb1/singles/C1--Trace--*.txt\"):\n",
    "        \"\"\"\n",
    "        Load CASB1 singles data from text files.\n",
    "        \"\"\"\n",
    "        files = glob.glob(path)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found matching pattern: {path}\")\n",
    "            return {}\n",
    "            \n",
    "        files_per_channel = {}\n",
    "        \n",
    "        for file in files:\n",
    "            try:\n",
    "                filename = os.path.basename(file)\n",
    "                match = re.search(r'C(\\d+)--Trace--(\\d+)', filename)\n",
    "                if match:\n",
    "                    channel = int(match.group(1))\n",
    "                    trace_num = int(match.group(2))\n",
    "                else:\n",
    "                    match = re.search(r'Trace--(\\d+)', filename)\n",
    "                    if match:\n",
    "                        trace_num = int(match.group(1))\n",
    "                        channel = 1  # Default if no channel in filename\n",
    "                    else:\n",
    "                        print(f\"Could not extract info from {filename}, skipping\")\n",
    "                        continue\n",
    "                \n",
    "                # Load data\n",
    "                df = pd.read_csv(file, skiprows=6, names=[\"time\", \"output\"])\n",
    "                for col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "                # Initialize channel structure if needed\n",
    "                if channel not in self.channels:\n",
    "                    self.channels[channel] = {}\n",
    "                \n",
    "                # Initialize singles dict if needed\n",
    "                if 'singles' not in self.channels[channel]:\n",
    "                    self.channels[channel]['singles'] = {}\n",
    "                \n",
    "                # Store the trace\n",
    "                self.channels[channel]['singles'][trace_num] = df\n",
    "                \n",
    "                # Update counter\n",
    "                if channel in files_per_channel:\n",
    "                    files_per_channel[channel] += 1\n",
    "                else:\n",
    "                    files_per_channel[channel] = 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "                \n",
    "        # Print summary\n",
    "        total_files = sum(files_per_channel.values())\n",
    "        print(f\"Loaded {total_files} singles files across {len(files_per_channel)} channels for {self.name}\")\n",
    "        \n",
    "        return files_per_channel\n",
    "    \n",
    "    def load_averages(self, path=\"../data/casb1/averages/ch*.csv\"):\n",
    "        \"\"\"\n",
    "        Load CASB1 averages data from CSV files.\n",
    "        \"\"\"\n",
    "        files = glob.glob(path)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found matching pattern: {path}\")\n",
    "            return {}\n",
    "            \n",
    "        files_per_channel = {}\n",
    "        \n",
    "        for file in files:\n",
    "            try:\n",
    "                filename = os.path.basename(file)\n",
    "                match = re.search(r'ch(\\d+)', filename)\n",
    "                if match:\n",
    "                    channel = int(match.group(1))\n",
    "                else:\n",
    "                    print(f\"Could not extract channel from {filename}, skipping\")\n",
    "                    continue\n",
    "                \n",
    "                # Extract trace number if available, otherwise use counter\n",
    "                if channel in files_per_channel:\n",
    "                    trace_num = files_per_channel[channel]\n",
    "                else:\n",
    "                    trace_num = 0\n",
    "                \n",
    "                # Load data\n",
    "                df = pd.read_csv(file, skiprows=21, names=[\"time\", \"output\", \"input\", \"CH3\"])\n",
    "                for col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "                # Keep relevant columns\n",
    "                df = df[[\"time\", \"output\", \"input\"]] if \"input\" in df.columns else df[[\"time\", \"output\"]]\n",
    "                \n",
    "                # Initialize channel structure if needed\n",
    "                if channel not in self.channels:\n",
    "                    self.channels[channel] = {}\n",
    "                \n",
    "                # Initialize averages dict if needed\n",
    "                if 'averages' not in self.channels[channel]:\n",
    "                    self.channels[channel]['averages'] = {}\n",
    "                \n",
    "                # Store the trace\n",
    "                self.channels[channel]['averages'][trace_num] = df\n",
    "                \n",
    "                # Update counter\n",
    "                if channel in files_per_channel:\n",
    "                    files_per_channel[channel] += 1\n",
    "                else:\n",
    "                    files_per_channel[channel] = 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "                \n",
    "        # Print summary\n",
    "        total_files = sum(files_per_channel.values())\n",
    "        print(f\"Loaded {total_files} averages files across {len(files_per_channel)} channels for {self.name}\")\n",
    "        \n",
    "        return files_per_channel\n",
    "    \n",
    "    def load_data(self, singles_path=None, averages_path=None):\n",
    "        \"\"\"\n",
    "        Load both singles and averages data.\n",
    "        \n",
    "        Args:\n",
    "            singles_path (str, optional): Path to singles files\n",
    "            averages_path (str, optional): Path to averages files\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Number of channels with singles data, number with averages data\n",
    "        \"\"\"\n",
    "        # Load singles if path provided\n",
    "        singles_result = {}\n",
    "        if singles_path:\n",
    "            singles_result = self.load_singles(singles_path)\n",
    "        \n",
    "        # Load averages if path provided\n",
    "        averages_result = {}\n",
    "        if averages_path:\n",
    "            averages_result = self.load_averages(averages_path)\n",
    "        \n",
    "        return len(singles_result), len(averages_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CASB2Processor(WaveformProcessor):\n",
    "    \"\"\"Processor for CASB2 board data.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"CASB2\")\n",
    "    \n",
    "    def load_singles(self, path=\"../data/casb2/singles/ch*/tek*ALL.csv\"):\n",
    "        \"\"\"\n",
    "        Load CASB2 singles data from CSV files.\n",
    "        \"\"\"\n",
    "        files = glob.glob(path)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found matching pattern: {path}\")\n",
    "            return {}\n",
    "            \n",
    "        files_per_channel = {}\n",
    "        \n",
    "        for file in files:\n",
    "            try:\n",
    "                filename = os.path.basename(file)\n",
    "                ch_dir = os.path.basename(os.path.dirname(file))\n",
    "                \n",
    "                # Try to extract channel from directory first\n",
    "                ch_match = re.search(r'ch(\\d+)', ch_dir)\n",
    "                if ch_match:\n",
    "                    channel = int(ch_match.group(1))\n",
    "                else:\n",
    "                    # Try from filename\n",
    "                    ch_match = re.search(r'ch(\\d+)', filename)\n",
    "                    if ch_match:\n",
    "                        channel = int(ch_match.group(1))\n",
    "                    else:\n",
    "                        print(f\"Could not extract channel from {file}, skipping\")\n",
    "                        continue\n",
    "                \n",
    "                # Extract trace number if available\n",
    "                trace_match = re.search(r'tek(\\d+)ALL', filename)\n",
    "                if trace_match:\n",
    "                    trace_num = int(trace_match.group(1))\n",
    "                else:\n",
    "                    # Use a counter based on how many files we've seen for this channel\n",
    "                    if channel in files_per_channel:\n",
    "                        trace_num = files_per_channel[channel]\n",
    "                    else:\n",
    "                        trace_num = 0\n",
    "                \n",
    "                # Read the data\n",
    "                df = pd.read_csv(file, skiprows=21, names=[\"time\", \"output\", \"input\", \"CH3\"])\n",
    "                \n",
    "                # Ensure numeric values\n",
    "                for col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "                # Keep only the columns we need\n",
    "                df = df[[\"time\", \"output\", \"input\"]] if \"input\" in df.columns else df[[\"time\", \"output\"]]\n",
    "                \n",
    "                # Initialize channel structure if needed\n",
    "                if channel not in self.channels:\n",
    "                    self.channels[channel] = {}\n",
    "                \n",
    "                # Initialize singles dict if needed\n",
    "                if 'singles' not in self.channels[channel]:\n",
    "                    self.channels[channel]['singles'] = {}\n",
    "                \n",
    "                # Store trace with its number\n",
    "                self.channels[channel]['singles'][trace_num] = df\n",
    "                \n",
    "                # Update counter\n",
    "                if channel in files_per_channel:\n",
    "                    files_per_channel[channel] += 1\n",
    "                else:\n",
    "                    files_per_channel[channel] = 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "        \n",
    "        # Print summary\n",
    "        total_files = sum(files_per_channel.values())\n",
    "        print(f\"Loaded {total_files} singles files across {len(files_per_channel)} channels for {self.name}\")\n",
    "        \n",
    "        return files_per_channel\n",
    "    \n",
    "    def load_averages(self, path=\"../data/casb2/averages/ch*/tek*ALL.csv\"):\n",
    "        \"\"\"\n",
    "        Load CASB2 averages data from CSV files.\n",
    "        \"\"\"\n",
    "        files = glob.glob(path)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found matching pattern: {path}\")\n",
    "            return {}\n",
    "            \n",
    "        files_per_channel = {}\n",
    "        \n",
    "        for file in files:\n",
    "            try:\n",
    "                filename = os.path.basename(file)\n",
    "                ch_dir = os.path.basename(os.path.dirname(file))\n",
    "                \n",
    "                # Try to extract channel from directory first\n",
    "                ch_match = re.search(r'ch(\\d+)', ch_dir)\n",
    "                if ch_match:\n",
    "                    channel = int(ch_match.group(1))\n",
    "                else:\n",
    "                    # Try from filename\n",
    "                    ch_match = re.search(r'ch(\\d+)', filename)\n",
    "                    if ch_match:\n",
    "                        channel = int(ch_match.group(1))\n",
    "                    else:\n",
    "                        print(f\"Could not extract channel from {file}, skipping\")\n",
    "                        continue\n",
    "                \n",
    "                # Extract trace number if available\n",
    "                trace_match = re.search(r'tek(\\d+)ALL', filename)\n",
    "                if trace_match:\n",
    "                    trace_num = int(trace_match.group(1))\n",
    "                else:\n",
    "                    # Use a counter based on how many files we've seen for this channel\n",
    "                    if channel in files_per_channel:\n",
    "                        trace_num = files_per_channel[channel]\n",
    "                    else:\n",
    "                        trace_num = 0\n",
    "                \n",
    "                # Read the data\n",
    "                df = pd.read_csv(file, skiprows=21, names=[\"time\", \"output\", \"input\", \"CH3\"])\n",
    "                \n",
    "                # Ensure numeric values\n",
    "                for col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "                # Keep only the columns we need\n",
    "                df = df[[\"time\", \"output\", \"input\"]] if \"input\" in df.columns else df[[\"time\", \"output\"]]\n",
    "                \n",
    "                # Initialize channel structure if needed\n",
    "                if channel not in self.channels:\n",
    "                    self.channels[channel] = {}\n",
    "                \n",
    "                # Initialize averages dict if needed\n",
    "                if 'averages' not in self.channels[channel]:\n",
    "                    self.channels[channel]['averages'] = {}\n",
    "                \n",
    "                # Store trace with its number\n",
    "                self.channels[channel]['averages'][trace_num] = df\n",
    "                \n",
    "                # Update counter\n",
    "                if channel in files_per_channel:\n",
    "                    files_per_channel[channel] += 1\n",
    "                else:\n",
    "                    files_per_channel[channel] = 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "        \n",
    "        # Print summary\n",
    "        total_files = sum(files_per_channel.values())\n",
    "        print(f\"Loaded {total_files} averages files across {len(files_per_channel)} channels for {self.name}\")\n",
    "        \n",
    "        return files_per_channel\n",
    "    \n",
    "    def load_data(self, singles_path=None, averages_path=None):\n",
    "        \"\"\"\n",
    "        Load both singles and averages data.\n",
    "        \n",
    "        Args:\n",
    "            singles_path (str, optional): Path to singles files\n",
    "            averages_path (str, optional): Path to averages files\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Number of channels with singles data, number with averages data\n",
    "        \"\"\"\n",
    "        # Load singles if path provided\n",
    "        singles_result = {}\n",
    "        if singles_path:\n",
    "            singles_result = self.load_singles(singles_path)\n",
    "        else:\n",
    "            singles_result = self.load_singles()  # Use default path\n",
    "        \n",
    "        # Load averages if path provided\n",
    "        averages_result = {}\n",
    "        if averages_path:\n",
    "            averages_result = self.load_averages(averages_path)\n",
    "        else:\n",
    "            averages_result = self.load_averages()  # Use default path\n",
    "        \n",
    "        return len(singles_result), len(averages_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MTCAProcessor(WaveformProcessor):\n",
    "    \"\"\"Processor for MTCA board data.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"MTCA\")\n",
    "    \n",
    "    def load_singles(self, path=\"../data/mtca1/singles/C4--Trace--*.txt\"):\n",
    "        \"\"\"\n",
    "        Load MTCA singles data from text files.\n",
    "        \"\"\"\n",
    "        files = glob.glob(path)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found matching pattern: {path}\")\n",
    "            return {}\n",
    "            \n",
    "        files_per_channel = {}\n",
    "        \n",
    "        for file in files:\n",
    "            try:\n",
    "                filename = os.path.basename(file)\n",
    "                \n",
    "                # Extract channel and trace info\n",
    "                match = re.search(r'C(\\d+)--Trace--(\\d+)', filename)\n",
    "                if match:\n",
    "                    channel = int(match.group(1))\n",
    "                    trace_num = int(match.group(2))\n",
    "                else:\n",
    "                    match = re.search(r'Trace--(\\d+)', filename)\n",
    "                    if match:\n",
    "                        trace_num = int(match.group(1))\n",
    "                        channel = 4  # Default if not specified\n",
    "                    else:\n",
    "                        print(f\"Could not extract info from {filename}, skipping\")\n",
    "                        continue\n",
    "                \n",
    "                # Load data - adjust skiprows based on your file format\n",
    "                df = pd.read_csv(file, skiprows=6, names=[\"time\", \"output\"])\n",
    "                for col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "                # Initialize channel structure if needed\n",
    "                if channel not in self.channels:\n",
    "                    self.channels[channel] = {}\n",
    "                \n",
    "                # Initialize singles dict if needed\n",
    "                if 'singles' not in self.channels[channel]:\n",
    "                    self.channels[channel]['singles'] = {}\n",
    "                \n",
    "                # Store the trace\n",
    "                self.channels[channel]['singles'][trace_num] = df\n",
    "                \n",
    "                # Update counter\n",
    "                if channel in files_per_channel:\n",
    "                    files_per_channel[channel] += 1\n",
    "                else:\n",
    "                    files_per_channel[channel] = 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "                \n",
    "        # Print summary\n",
    "        total_files = sum(files_per_channel.values())\n",
    "        print(f\"Loaded {total_files} singles files across {len(files_per_channel)} channels for {self.name}\")\n",
    "        \n",
    "        return files_per_channel\n",
    "    \n",
    "    def load_averages(self, path=\"../data/mtca1/averages/ch*.csv\"):\n",
    "        \"\"\"\n",
    "        Load MTCA averages data from CSV files.\n",
    "        \"\"\"\n",
    "        files = glob.glob(path)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found matching pattern: {path}\")\n",
    "            return {}\n",
    "            \n",
    "        files_per_channel = {}\n",
    "        \n",
    "        for file in files:\n",
    "            try:\n",
    "                filename = os.path.basename(file)\n",
    "                match = re.search(r'ch(\\d+)', filename)\n",
    "                if match:\n",
    "                    channel = int(match.group(1))\n",
    "                else:\n",
    "                    print(f\"Could not extract channel from {filename}, skipping\")\n",
    "                    continue\n",
    "                \n",
    "                # Extract trace number if available, otherwise use counter\n",
    "                if channel in files_per_channel:\n",
    "                    trace_num = files_per_channel[channel]\n",
    "                else:\n",
    "                    trace_num = 0\n",
    "                \n",
    "                # Load data - adjust skiprows and column names based on your file format\n",
    "                df = pd.read_csv(file)\n",
    "                \n",
    "                # Find time and output columns\n",
    "                time_col = None\n",
    "                output_col = None\n",
    "                \n",
    "                for col in df.columns:\n",
    "                    if col.lower() in (\"time\", \"times\"):\n",
    "                        time_col = col\n",
    "                    elif col.lower() in (\"output\", \"amplitude\", \"waveform\"):\n",
    "                        output_col = col\n",
    "                \n",
    "                if not time_col or not output_col:\n",
    "                    print(f\"Could not identify time/output columns in {filename}, using first two columns\")\n",
    "                    time_col = df.columns[0]\n",
    "                    output_col = df.columns[1]\n",
    "                \n",
    "                # Create new dataframe with standardized column names\n",
    "                new_df = pd.DataFrame({\n",
    "                    \"time\": pd.to_numeric(df[time_col], errors='coerce'),\n",
    "                    \"output\": pd.to_numeric(df[output_col], errors='coerce')\n",
    "                })\n",
    "                \n",
    "                # Initialize channel structure if needed\n",
    "                if channel not in self.channels:\n",
    "                    self.channels[channel] = {}\n",
    "                \n",
    "                # Initialize averages dict if needed\n",
    "                if 'averages' not in self.channels[channel]:\n",
    "                    self.channels[channel]['averages'] = {}\n",
    "                \n",
    "                # Store the trace\n",
    "                self.channels[channel]['averages'][trace_num] = new_df\n",
    "                \n",
    "                # Update counter\n",
    "                if channel in files_per_channel:\n",
    "                    files_per_channel[channel] += 1\n",
    "                else:\n",
    "                    files_per_channel[channel] = 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "                \n",
    "        # Print summary\n",
    "        total_files = sum(files_per_channel.values())\n",
    "        print(f\"Loaded {total_files} averages files across {len(files_per_channel)} channels for {self.name}\")\n",
    "        \n",
    "        return files_per_channel\n",
    "    \n",
    "    def load_data(self, singles_path=None, averages_path=None):\n",
    "        \"\"\"\n",
    "        Load both singles and averages data.\n",
    "        \n",
    "        Args:\n",
    "            singles_path (str, optional): Path to singles files\n",
    "            averages_path (str, optional): Path to averages files\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Number of channels with singles data, number with averages data\n",
    "        \"\"\"\n",
    "        # Load singles if path provided\n",
    "        singles_result = {}\n",
    "        if singles_path:\n",
    "            singles_result = self.load_singles(singles_path)\n",
    "        else:\n",
    "            singles_result = self.load_singles()  # Use default path\n",
    "        \n",
    "        # Load averages if path provided\n",
    "        averages_result = {}\n",
    "        if averages_path:\n",
    "            averages_result = self.load_averages(averages_path)\n",
    "        else:\n",
    "            try:\n",
    "                averages_result = self.load_averages()  # Use default path\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load averages with default path: {e}\")\n",
    "        \n",
    "        return len(singles_result), len(averages_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_combined_delays(boards, waveform_type='averages', trace_index=0, highlight_extremes=True):\n",
    "    \"\"\"\n",
    "    Create a combined bar plot showing delays from multiple boards.\n",
    "    \n",
    "    Args:\n",
    "        boards (list): List of WaveformProcessor instances\n",
    "        waveform_type (str): 'singles' or 'averages'\n",
    "        trace_index (int): Index of the trace to use\n",
    "        highlight_extremes (bool): Whether to highlight min/max delays\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The figure object\n",
    "    \"\"\"\n",
    "    # Make sure all boards have delay analysis\n",
    "    for board in boards:\n",
    "        channels_with_delays = 0\n",
    "        for ch in board.channels:\n",
    "            if ('analysis' in board.channels[ch] and \n",
    "                'delay' in board.channels[ch]['analysis']):\n",
    "                channels_with_delays += 1\n",
    "        \n",
    "        if channels_with_delays == 0:\n",
    "            print(f\"Calculating delays for {board.name} using {waveform_type}[{trace_index}]\")\n",
    "            try:\n",
    "                board.calculate_delays(waveform_type, trace_index)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not calculate delays for {board.name}: {e}\")\n",
    "    \n",
    "    # Get all channels across all boards\n",
    "    all_channels = set()\n",
    "    for board in boards:\n",
    "        all_channels.update(board.channels.keys())\n",
    "    all_channels = sorted(list(all_channels))\n",
    "    \n",
    "    # Create labels\n",
    "    labels = [f\"CH{ch}\" for ch in all_channels]\n",
    "    \n",
    "    # Set up the plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Calculate positions for bars\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.8 / len(boards)  # Width of the bars, adjusted for number of boards\n",
    "    \n",
    "    # Plot bars for each board\n",
    "    legend_items = []\n",
    "    \n",
    "    for i, board in enumerate(boards):\n",
    "        # Create dictionary mapping channel to delay\n",
    "        delay_dict = {}\n",
    "        for ch in board.channels:\n",
    "            if ('analysis' in board.channels[ch] and \n",
    "                'delay' in board.channels[ch]['analysis']):\n",
    "                delay_dict[ch] = board.channels[ch]['analysis']['delay']['value']\n",
    "        \n",
    "        # Fill in delays for all channels (use NaN for missing channels)\n",
    "        delays = [delay_dict.get(ch, np.nan) for ch in all_channels]\n",
    "        \n",
    "        # Calculate position adjustment\n",
    "        pos_adjustment = width * (i - (len(boards) - 1) / 2)\n",
    "        \n",
    "        # Create bars\n",
    "        bars = ax.bar(x + pos_adjustment, delays, width, label=board.name)\n",
    "        \n",
    "        if highlight_extremes:\n",
    "            # Find non-NaN values\n",
    "            valid_delays = [(idx, d) for idx, d in enumerate(delays) if not np.isnan(d)]\n",
    "            if valid_delays:\n",
    "                valid_indices, valid_values = zip(*valid_delays)\n",
    "                \n",
    "                # Find min (excluding 0 which might be reference)\n",
    "                non_zero_values = [d for d in valid_values if d != 0]\n",
    "                if non_zero_values:\n",
    "                    min_val = min(non_zero_values)\n",
    "                    min_idx = valid_indices[valid_values.index(min_val)]\n",
    "                    max_val = max(valid_values)\n",
    "                    max_idx = valid_indices[valid_values.index(max_val)]\n",
    "                    \n",
    "                    # Highlight min/max bars\n",
    "                    bars[min_idx].set_color('lightgreen')\n",
    "                    bars[max_idx].set_color('tomato')\n",
    "                    \n",
    "                    # Add value labels\n",
    "                    ax.text(x[min_idx] + pos_adjustment, delays[min_idx]+20, \n",
    "                           f\"{delays[min_idx]:.0f}\", ha='center', rotation=90, fontsize=8)\n",
    "                    ax.text(x[max_idx] + pos_adjustment, delays[max_idx]+20, \n",
    "                           f\"{delays[max_idx]:.0f}\", ha='center', rotation=90, fontsize=8)\n",
    "        \n",
    "        # Calculate standard deviation for legend\n",
    "        valid_delays = [d for d in delays if not np.isnan(d) and d != 0]\n",
    "        std_dev = np.std(valid_delays) if valid_delays else 0\n",
    "        legend_items.append(f'{board.name} ($\\\\sigma= {std_dev:.2f}$)')\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_xlabel(\"Channel\")\n",
    "    ax.set_ylabel(\"Delay Relative to Reference Channel [ps]\")\n",
    "    ax.set_title(f\"Unity Path Relative Channel Delays Comparison ({waveform_type})\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=90)\n",
    "    \n",
    "    # Find appropriate y-limit - skip NaN and inf values\n",
    "    all_delays = []\n",
    "    for board in boards:\n",
    "        for ch in board.channels:\n",
    "            if ('analysis' in board.channels[ch] and \n",
    "                'delay' in board.channels[ch]['analysis']):\n",
    "                value = board.channels[ch]['analysis']['delay']['value']\n",
    "                if not np.isnan(value) and not np.isinf(value):\n",
    "                    all_delays.append(value)\n",
    "    \n",
    "    if all_delays:\n",
    "        max_delay = max(all_delays)\n",
    "        ax.set_ylim(0, max_delay * 1.2)  # Add 20% margin\n",
    "    \n",
    "    # Add legend with standard deviations\n",
    "    ax.legend(legend_items)\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 401 singles files across 20 channels for CASB2\n",
      "Warning: No files found matching pattern: ../data/casb2/averages/ch*/tek*ALL.csv\n",
      "Loaded 35 singles files across 1 channels for MTCA\n",
      "Warning: No files found matching pattern: ../data/mtca1/averages/ch*.csv\n",
      "Channel 1: Rise time = 0.00 ns\n",
      "Channel 2: Rise time = 0.00 ns\n",
      "Channel 6: Rise time = 0.00 ns\n",
      "Channel 14: Rise time = 0.00 ns\n",
      "Channel 17: Rise time = 0.00 ns\n",
      "Channel 10: Rise time = 0.00 ns\n",
      "Channel 20: Rise time = 0.00 ns\n",
      "Channel 9: Rise time = 0.00 ns\n",
      "Channel 19: Rise time = 0.00 ns\n",
      "Channel 3: Rise time = 0.00 ns\n",
      "Channel 11: Rise time = 0.00 ns\n",
      "Channel 13: Rise time = 0.00 ns\n",
      "Channel 5: Rise time = 0.00 ns\n",
      "Channel 8: Rise time = 0.00 ns\n",
      "Channel 12: Rise time = 0.00 ns\n",
      "Channel 16: Rise time = 0.00 ns\n",
      "Channel 4: Rise time = 0.00 ns\n",
      "Channel 15: Rise time = 0.00 ns\n",
      "Channel 7: Rise time = 0.00 ns\n",
      "Channel 18: Rise time = 0.00 ns\n",
      "Channel 4: Rise time = nan ns\n",
      "No rise time measurements found. Calculating...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to calculate rise times. Cannot calculate delays.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_158938/754614247.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Calculate delays using averages data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mcasb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_delays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'averages'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mcasb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_delays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'averages'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmtca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_delays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'averages'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_158938/3187126854.py\u001b[0m in \u001b[0;36mcalculate_delays\u001b[0;34m(self, waveform_type, trace_index, reference_channel)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchannels_with_rt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to calculate rise times. Cannot calculate delays.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# Find reference channel if not specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to calculate rise times. Cannot calculate delays."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example of how to use the classes:\n",
    "\n",
    "# Initialize processors\n",
    "casb1 = CASB1Processor()\n",
    "casb2 = CASB2Processor()\n",
    "mtca = MTCAProcessor()\n",
    "\n",
    "# Load data\n",
    "casb1.load_data()\n",
    "casb2.load_data()\n",
    "mtca.load_data()\n",
    "\n",
    "# Calculate rise times using singles data\n",
    "casb1.calculate_all_rise_times(waveform_type='singles', trace_index=0)\n",
    "casb2.calculate_all_rise_times(waveform_type='singles', trace_index=0)\n",
    "mtca.calculate_all_rise_times(waveform_type='singles', trace_index=0)\n",
    "\n",
    "# Calculate delays using averages data\n",
    "casb1.calculate_delays(waveform_type='averages', trace_index=0)\n",
    "casb2.calculate_delays(waveform_type='averages', trace_index=0)\n",
    "mtca.calculate_delays(waveform_type='averages', trace_index=0)\n",
    "\n",
    "# Calculate gains using averages data\n",
    "casb1.calculate_gains(waveform_type='averages', trace_index=0)\n",
    "casb2.calculate_gains(waveform_type='averages', trace_index=0)\n",
    "mtca.calculate_gains(waveform_type='averages', trace_index=0)\n",
    "\n",
    "# Plot a sample waveform\n",
    "casb1.plot_waveform(channel=1, waveform_type='singles', trace_index=0, show_thresholds=True)\n",
    "\n",
    "# Plot delays for individual boards\n",
    "casb1.plot_delays(highlight_extremes=True)\n",
    "casb2.plot_delays(highlight_extremes=True)\n",
    "\n",
    "# Plot combined delays\n",
    "plot_combined_delays([casb1, casb2, mtca], waveform_type='averages', trace_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
