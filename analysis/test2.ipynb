{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveformProcessor:\n",
    "    \"\"\"\n",
    "    Base class for storing and processing waveform data from different boards\n",
    "    \"\"\"\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name or \"Unnamed\"\n",
    "        self.channels = {}  # Main data structure\n",
    "\n",
    "    def get_available_channels(self):\n",
    "        return sorted(list(self.channels.keys()))\n",
    "\n",
    "    def get_trace_data(self, waveform_type, channel, trace_index):\n",
    "        if channel not in self.channels:\n",
    "            raise ValueError(f\"Channel {channel} not found\")  \n",
    "        if waveform_type not in self.channels[channel]:\n",
    "            raise ValueError(f\"Channel {channel} does not have {waveform_type} data\")\n",
    "        if trace_index not in self.channels[channel][waveform_type]:\n",
    "            raise ValueError(f\"Channel {channel} does not have trace {trace_index} in {waveform_type} data. There are {len(self.channels[channel][waveform_type].keys())} traces available.\")\n",
    "        return self.channels[channel][waveform_type][trace_index]['data']\n",
    "\n",
    "    def get_trace_analysis(self, waveform_type, channel, trace_index):\n",
    "        if channel not in self.channels:\n",
    "            raise ValueError(f\"Channel {channel} not found\")  \n",
    "        if waveform_type not in self.channels[channel]:\n",
    "            raise ValueError(f\"Channel {channel} does not have {waveform_type} data\")\n",
    "        if trace_index not in self.channels[channel][waveform_type]:\n",
    "            raise ValueError(f\"Channel {channel} does not have trace {trace_index} in {waveform_type} data. There are {len(self.channels[channel][waveform_type].keys())} traces available.\")\n",
    "        return self.channels[channel][waveform_type][trace_index]['analysis']\n",
    "\n",
    "    def get_pedestal(self, data, baseline_start_pct, baseline_end_pct):\n",
    "        start_idx = int(len(data) * baseline_start_pct)\n",
    "        end_idx = int(len(data) * baseline_end_pct)\n",
    "        return np.mean(data[start_idx:end_idx+1])\n",
    "\n",
    "    def getPeakIndex(self, data, baseline_start_pct, baseline_end_pct, threshold, true_peak=False):\n",
    "        peak_value = 0\n",
    "        peak_index = 0\n",
    "        threshold_index = 0\n",
    "        crossed_threshold = False\n",
    "        counter = 0\n",
    "        counter_max = 2 \n",
    "        ## May want to add a counter_max for different scope resolutions    \n",
    "        # if self.name=='CASB1':\n",
    "        #     counter_max = 8 # traces sampled with 100 ps resolution scope -\n",
    "        # elif self.name=='CASB2': \n",
    "        #     counter_max = 2 # traces sampled with 400 ps resulution scope \n",
    "    \n",
    "        pedestal = self.get_pedestal(data, baseline_start_pct, baseline_end_pct)\n",
    "        for i in range(len(data)):\n",
    "            if not crossed_threshold and data[i]-pedestal>threshold:\n",
    "                crossed_threshold = True\n",
    "                threshold_index = i\n",
    "            if crossed_threshold and data[i]<=peak_value:\n",
    "                counter += 1\n",
    "            if crossed_threshold and data[i]>peak_value:\n",
    "                peak_value = data[i]\n",
    "                peak_index = i\n",
    "            if crossed_threshold and counter>counter_max:\n",
    "                break\n",
    "\n",
    "        if true_peak:\n",
    "            peak_index = np.argmax(data)\n",
    "            \n",
    "        return peak_index, threshold_index\n",
    "\n",
    "    \n",
    "    def getLowCrossingTime(self,time,data,thresh,start_i):\n",
    "        over=0\n",
    "        under=0\n",
    "        for i in range(start_i,-1,-1):\n",
    "            if data[i]<thresh:\n",
    "                under=i\n",
    "                over=i+1\n",
    "                break\n",
    "        m=(data[over]-data[under])/(time[over]-time[under])\n",
    "        cross_time=time[under]+((thresh-data[under])/m)\n",
    "        return cross_time\n",
    "\n",
    "    def getHighCrossingTime(self,time,data,thresh,start_i):\n",
    "        over=0\n",
    "        under=0\n",
    "        for i in range(start_i,len(data)):\n",
    "            if data[i]>thresh:\n",
    "                over=i\n",
    "                under=i-1\n",
    "                break\n",
    "        m=(data[over]-data[under])/(time[over]-time[under])\n",
    "        cross_time=time[under]+((thresh-data[under])/m)\n",
    "        return cross_time\n",
    "\n",
    "    def calculate_rise_time(self, channel, waveform_type, trace_index, baseline_start_pct, baseline_end_pct, threshold, low_pct, high_pct,output,input):\n",
    "        df = self.get_trace_data(waveform_type, channel, trace_index)\n",
    "        time = df[\"time\"].values * 1e9 # Convert to ns\n",
    "        if output:\n",
    "            signal = df[\"output\"].values * 1e3 # Convert to mV\n",
    "        elif input:\n",
    "            signal = df[\"input\"].values * 1e3 # Convert to mV\n",
    "        pedestal = self.get_pedestal(signal, baseline_start_pct, baseline_end_pct)\n",
    "        peak_index,threshold_index = self.getPeakIndex(signal, baseline_start_pct, baseline_end_pct, threshold)\n",
    "        amplitude = signal[peak_index] - pedestal\n",
    "        low_threshold = pedestal + amplitude * low_pct \n",
    "        high_threshold = pedestal + amplitude * high_pct\n",
    "        t_low=self.getLowCrossingTime(time,signal,low_threshold,threshold_index)\n",
    "        t_high=self.getHighCrossingTime(time,signal,high_threshold,threshold_index)\n",
    "        rise_time = t_high - t_low\n",
    "        if output:\n",
    "            analysis_dict = self.channels[channel][waveform_type][trace_index].get('analysis', {})\n",
    "            analysis_dict.update({\n",
    "                \"output_rise_time\": rise_time,\n",
    "                \"output_t_low\": t_low,\n",
    "                \"output_t_high\": t_high,\n",
    "                \"output_peak\": signal[peak_index],\n",
    "                \"output_peak_index\": peak_index,\n",
    "                \"output_pedestal\": pedestal\n",
    "            })\n",
    "            self.channels[channel][waveform_type][trace_index]['analysis'] = analysis_dict\n",
    "        elif input:\n",
    "            analysis_dict = self.channels[channel][waveform_type][trace_index].get('analysis', {})\n",
    "            analysis_dict.update({\n",
    "                \"input_rise_time\": rise_time,\n",
    "                \"input_t_low\": t_low,\n",
    "                \"input_t_high\": t_high,\n",
    "                \"input_peak\": signal[peak_index],\n",
    "                \"input_peak_index\": peak_index,\n",
    "                \"input_pedestal\": pedestal\n",
    "            })\n",
    "            self.channels[channel][waveform_type][trace_index]['analysis'] = analysis_dict\n",
    "        else:\n",
    "            raise ValueError(\"Please specify if a CASB input or output trace is being analyzed\")\n",
    "        return rise_time, t_low, t_high\n",
    "    \n",
    "    def calculate_all_rise_times(self, waveform_type, baseline_start_pct, baseline_end_pct, threshold, low_pct, high_pct,output,input):\n",
    "        results = {}\n",
    "        for channel in self.channels:\n",
    "            try:\n",
    "                if waveform_type in self.channels[channel]:\n",
    "                    for trace_index in range(len(self.channels[channel][waveform_type])):\n",
    "                        rt, t_low, t_high = self.calculate_rise_time(channel,waveform_type,trace_index,baseline_start_pct,baseline_end_pct,threshold,low_pct,high_pct,output,input)\n",
    "                        results[channel] = rt\n",
    "                else:\n",
    "                    results[channel] = np.nan\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {self.name} {waveform_type} channel {channel}: {e}\")\n",
    "                results[channel] = np.nan\n",
    "        return results\n",
    "    \n",
    "    # def calculate_delays(self, waveform_type='averages', trace_index=0, reference_channel=None):\n",
    "    #     channels_with_rt = {}\n",
    "    #     for ch in self.channels:\n",
    "    #         if ('analysis' in self.channels[ch] and \n",
    "    #             'rise_time' in self.channels[ch]['analysis']):\n",
    "    #             channels_with_rt[ch] = self.channels[ch]['analysis']['rise_time']\n",
    "    #     if not channels_with_rt:\n",
    "    #         print(\"No rise time measurements found. Calculating...\")\n",
    "    #         self.calculate_all_rise_times(waveform_type, trace_index)\n",
    "    #         channels_with_rt = {}\n",
    "    #         for ch in self.channels:\n",
    "    #             if ('analysis' in self.channels[ch] and \n",
    "    #                 'rise_time' in self.channels[ch]['analysis']):\n",
    "    #                 channels_with_rt[ch] = self.channels[ch]['analysis']['rise_time']\n",
    "    #         if not channels_with_rt:\n",
    "    #             raise ValueError(\"Failed to calculate rise times. Cannot calculate delays.\")\n",
    "    #     if reference_channel is None:\n",
    "    #         min_rt = float('inf')\n",
    "    #         for ch, rt_data in channels_with_rt.items():\n",
    "    #             if not np.isnan(rt_data['value']) and rt_data['value'] < min_rt:\n",
    "    #                 min_rt = rt_data['value']\n",
    "    #                 reference_channel = ch\n",
    "    #         if reference_channel is None:\n",
    "    #             raise ValueError(\"No valid rise time found for any channel.\")\n",
    "    #     if reference_channel not in channels_with_rt:\n",
    "    #         raise ValueError(f\"Reference channel {reference_channel} has no rise time data\")\n",
    "    #     ref_t_low = channels_with_rt[reference_channel]['t_low']\n",
    "    #     delays = {}\n",
    "    #     for ch in self.channels:\n",
    "    #         if ('analysis' in self.channels[ch][waveform_type][trace_index] and \n",
    "    #             'rise_time' in self.channels[ch][waveform_type][trace_index]['analysis'] and \n",
    "    #             not np.isnan(self.channels[ch][waveform_type][trace_index]['analysis']['rise_time']['t_low'])):\n",
    "    #             ch_t_low = self.channels[ch]['analysis']['rise_time']['t_low']\n",
    "    #             delay_ps = (ch_t_low - ref_t_low) * 1e12\n",
    "    #             if 'analysis' not in self.channels[ch]:\n",
    "    #                 self.channels[ch]['analysis'] = {}\n",
    "    #             self.channels[ch]['analysis']['delay'] = {\n",
    "    #                 'value': delay_ps,\n",
    "    #                 'reference_channel': reference_channel,\n",
    "    #                 'source': waveform_type,\n",
    "    #                 'trace_index': trace_index\n",
    "    #             }\n",
    "    #             delays[ch] = delay_ps\n",
    "    #         else:\n",
    "    #             delays[ch] = np.nan\n",
    "    #     return delays\n",
    "    \n",
    "    # def calculate_gains(self, waveform_type='averages', trace_index=0):\n",
    "    #     gains = {}\n",
    "    #     for ch in self.channels:\n",
    "    #         try:\n",
    "    #             if (waveform_type in self.channels[ch] and \n",
    "    #                 trace_index in self.channels[ch][waveform_type]):\n",
    "    #                 df = self.get_trace_data(waveform_type, ch, trace_index)\n",
    "    #                 if \"input\" in df.columns and (\"output\" in df.columns or \"amplitude\" in df.columns):\n",
    "    #                     input_signal = df[\"input\"].values\n",
    "    #                     output_signal = df[\"amplitude\"].values if \"amplitude\" in df.columns else df[\"output\"].values\n",
    "    #                     input_pedestal = self.get_pedestal(input_signal)\n",
    "    #                     output_pedestal = self.get_pedestal(output_signal)\n",
    "    #                     input_adj = input_signal - input_pedestal\n",
    "    #                     output_adj = output_signal - output_pedestal\n",
    "    #                     input_peak = np.max(np.abs(input_adj))\n",
    "    #                     output_peak = np.max(np.abs(output_adj))\n",
    "    #                     if input_peak != 0:\n",
    "    #                         gain = output_peak / input_peak\n",
    "    #                     else:\n",
    "    #                         gain = np.nan\n",
    "    #                     if 'analysis' not in self.channels[ch]:\n",
    "    #                         self.channels[ch]['analysis'] = {}\n",
    "    #                     self.channels[ch]['analysis']['gain'] = {\n",
    "    #                         'value': gain,\n",
    "    #                         'input_peak': input_peak,\n",
    "    #                         'output_peak': output_peak,\n",
    "    #                         'source': waveform_type,\n",
    "    #                         'trace_index': trace_index\n",
    "    #                     }\n",
    "    #                     gains[ch] = gain\n",
    "    #                     print(f\"Channel {ch}: Gain = {gain:.4f}\")\n",
    "    #                 else:\n",
    "    #                     print(f\"Channel {ch} missing input or output data\")\n",
    "    #                     gains[ch] = np.nan\n",
    "    #             else:\n",
    "    #                 print(f\"No {waveform_type} data for channel {ch} at index {trace_index}\")\n",
    "    #                 gains[ch] = np.nan\n",
    "    #         except Exception as e:\n",
    "    #             print(f\"Error calculating gain for channel {ch}: {e}\")\n",
    "    #             gains[ch] = np.nan\n",
    "    #     return gains\n",
    "    \n",
    "    def plot_waveform(self, channel, waveform_type, trace_index, show_rise_time_analysis,output,input):\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        df = self.get_trace_data(waveform_type, channel, trace_index)\n",
    "        analysis = self.get_trace_analysis(waveform_type, channel, trace_index)\n",
    "        time_ns = df[\"time\"].values*1e9  \n",
    "        if output:\n",
    "            signal_mV = df[\"output\"].values*1e3\n",
    "            ax.plot(time_ns, signal_mV - analysis['output_pedestal'],color='blue',label=f\"rt={analysis['output_rise_time']:.2f} ns\")\n",
    "            if (show_rise_time_analysis):\n",
    "                ax.axvline(x=analysis['output_t_low'], color='blue', linestyle='--') \n",
    "                ax.axvline(x=analysis['output_t_high'], color='blue', linestyle='--') \n",
    "                ax.axhline(y=0, color='grey', linestyle='--')\n",
    "                ax.axhline(y=analysis['output_peak']-analysis['output_pedestal'], color='blue', linestyle='--')\n",
    "        if input:\n",
    "            signal_mV = df[\"input\"].values*1e3\n",
    "            ax.plot(time_ns, signal_mV - analysis['input_pedestal'],color='orange',label=f\"rt={analysis['input_rise_time']:.2f} ns\")\n",
    "            if (show_rise_time_analysis):\n",
    "                ax.axvline(x=analysis['input_t_low'], color='orange', linestyle='--') \n",
    "                ax.axvline(x=analysis['input_t_high'], color='orange', linestyle='--') \n",
    "                ax.axhline(y=0, color='grey', linestyle='--')\n",
    "                ax.axhline(y=analysis['input_peak']-analysis['input_pedestal'], color='orange', linestyle='--')\n",
    "        ax.set_xlabel(\"Time (ns)\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.set_title(f\"{self.name} Channel {channel} {waveform_type} Trace {trace_index} \")\n",
    "        ax.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        return fig\n",
    "\n",
    "    def plot_all_waveforms(self, waveform_type, show_rise_time_analysis=False,output=True,input=False):\n",
    "        available_traces = []\n",
    "        for channel in self.channels:\n",
    "            if waveform_type in self.channels[channel]:\n",
    "                for trace_index in range(len(self.channels[channel][waveform_type])):\n",
    "                    available_traces.append(self.channels[channel][waveform_type][trace_index])\n",
    "        n_cols = 4\n",
    "        n_rows = len(available_traces)//n_cols+1\n",
    "        fig, axs = plt.subplots(n_rows, n_cols, figsize=(20,5*n_rows))\n",
    "        for i, trace in enumerate(available_traces):\n",
    "            df=trace['data']\n",
    "            analysis=trace['analysis']\n",
    "            ax = axs[i//n_cols, i%n_cols]\n",
    "            if output:\n",
    "                ax.plot(df['time']*1e9, df['output']*1e3-analysis['output_pedestal'],color='blue',label=f\"rt={analysis['output_rise_time']:.2f} ns\")\n",
    "                if show_rise_time_analysis:\n",
    "                    ax.axvline(x=analysis['output_t_low'], color='blue', linestyle='--')\n",
    "                    ax.axvline(x=analysis['output_t_high'], color='blue', linestyle='--') \n",
    "                    ax.axhline(y=0, color='grey', linestyle='--')\n",
    "                    ax.axhline(y=analysis['output_peak']-analysis['output_pedestal'], color='blue', linestyle='--')\n",
    "            if input:\n",
    "                ax.plot(df['time']*1e9, df['input']*1e3-analysis['input_pedestal'],color='orange',label=f\"rt={analysis['input_rise_time']:.2f} ns\")\n",
    "                if show_rise_time_analysis:\n",
    "                    ax.axvline(x=analysis['input_t_low'], color='orange', linestyle='--')\n",
    "                    ax.axvline(x=analysis['input_t_high'], color='orange', linestyle='--') \n",
    "                    ax.axhline(y=0, color='grey', linestyle='--')\n",
    "                    ax.axhline(y=analysis['input_peak']-analysis['input_pedestal'], color='orange', linestyle='--')\n",
    "            ax.set_title(f\"{self.name} channel {channel} {waveform_type} trace {i} \")\n",
    "            ax.set_xlabel('Time (ns)')\n",
    "            ax.set_ylabel('Amplitude (mV)')\n",
    "            ax.legend()\n",
    "        plt.tight_layout\n",
    "\n",
    "    # def plot_delays(self, highlight_extremes=True):\n",
    "    #     channels_with_delays = {}\n",
    "    #     for ch in self.channels:\n",
    "    #         if ('analysis' in self.channels[ch] and \n",
    "    #             'delay' in self.channels[ch]['analysis']):\n",
    "    #             channels_with_delays[ch] = self.channels[ch]['analysis']['delay']['value']\n",
    "    #     if not channels_with_delays:\n",
    "    #         raise ValueError(\"No delay measurements found. Run calculate_delays first.\")\n",
    "    #     ch_nums = sorted(list(channels_with_delays.keys()))\n",
    "    #     labels = [f\"CH{ch}\" for ch in ch_nums]\n",
    "    #     delays = [channels_with_delays[ch] for ch in ch_nums]\n",
    "    #     fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    #     bars = ax.bar(labels, delays)\n",
    "    #     if highlight_extremes:\n",
    "    #         non_zero_delays = [d for d in delays if d != 0]\n",
    "    #         if non_zero_delays:\n",
    "    #             min_idx = delays.index(min(non_zero_delays))\n",
    "    #             max_idx = delays.index(max(delays))\n",
    "    #             if min_idx == delays.index(0):  # If the minimum is the reference channel (0 delay)\n",
    "    #                 temp_values = delays.copy()\n",
    "    #                 temp_values[min_idx] = float('inf')\n",
    "    #                 min_idx = temp_values.index(min(temp_values))\n",
    "    #             bars[min_idx].set_color('lightgreen')\n",
    "    #             bars[max_idx].set_color('tomato')\n",
    "    #             ax.text(min_idx, delays[min_idx]+20, f\"{delays[min_idx]:.0f}\", \n",
    "    #                    ha='center', rotation=90)\n",
    "    #             ax.text(max_idx, delays[max_idx]+20, f\"{delays[max_idx]:.0f}\", \n",
    "    #                    ha='center', rotation=90)\n",
    "    #     std_dev = np.std([d for d in delays if not np.isnan(d) and d != 0])\n",
    "    #     ax.set_xlabel(\"Channel\")\n",
    "    #     ax.set_ylabel(\"Delay Relative to Reference Channel [ps]\")\n",
    "    #     ax.set_title(f\"{self.name} Unity Path Relative Channel Delays\")\n",
    "    #     ax.set_ylim(0, max(delays) * 1.2)  # Add 20% margin\n",
    "    #     ax.legend([f'$\\\\sigma= {std_dev:.2f}$'])\n",
    "    #     ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    #     plt.tight_layout()\n",
    "    #     return fig\n",
    "    \n",
    "    # def plot_multiple_traces(self, channel, waveform_type='singles', max_traces=5, ax=None):\n",
    "    #     if channel not in self.channels or waveform_type not in self.channels[channel]:\n",
    "    #         raise ValueError(f\"No {waveform_type} data found for channel {channel}\")\n",
    "    #     traces = self.channels[channel][waveform_type]\n",
    "    #     if not traces:\n",
    "    #         raise ValueError(f\"No traces found for channel {channel} in {wf_type}\")\n",
    "    #     if ax is None:\n",
    "    #         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    #     trace_nums = sorted(list(traces.keys()))[:max_traces]\n",
    "    #     for i, trace_num in enumerate(trace_nums):\n",
    "    #         df = traces[trace_num]\n",
    "    #         if \"output\" in df.columns:\n",
    "    #             label = f\"Trace {trace_num}\"\n",
    "    #             ax.plot(df[\"time\"] * 1e9, df[\"output\"], label=label, alpha=0.7)\n",
    "    #         elif \"amplitude\" in df.columns:\n",
    "    #             label = f\"Trace {trace_num}\"\n",
    "    #             ax.plot(df[\"time\"] * 1e9, df[\"amplitude\"], label=label, alpha=0.7)\n",
    "    #     ax.set_xlabel(\"Time (ns)\")\n",
    "    #     ax.set_ylabel(\"Output\")\n",
    "    #     ax.set_title(f\"{self.name} Channel {channel} - {waveform_type.capitalize()} Traces\")\n",
    "    #     ax.grid(True)\n",
    "    #     ax.legend()\n",
    "    #     return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CASB1Processor(WaveformProcessor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"CASB1\")\n",
    "    \n",
    "    def load_singles(self, path=\"../data/casb1/singles/C1--Trace--*.txt\"):\n",
    "        files = glob.glob(path)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found matching pattern: {path}\")\n",
    "            return {}\n",
    "        files_per_channel = {}\n",
    "        for file in files:\n",
    "            try:\n",
    "                filename = os.path.basename(file)\n",
    "                match = re.search(r'C(\\d+)--Trace--(\\d+)', filename)\n",
    "                if match:\n",
    "                    channel = int(match.group(1))\n",
    "                    trace_num = int(match.group(2))\n",
    "                else:\n",
    "                    match = re.search(r'Trace--(\\d+)', filename)\n",
    "                    if match:\n",
    "                        trace_num = int(match.group(1))\n",
    "                        channel = 1  # Default if no channel in filename\n",
    "                    else:\n",
    "                        print(f\"Could not extract info from {filename}, skipping\")\n",
    "                        continue\n",
    "                df = pd.read_csv(file, skiprows=6, names=[\"time\", \"output\"])\n",
    "                for col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                if channel not in self.channels:\n",
    "                    self.channels[channel] = {}\n",
    "                if 'singles' not in self.channels[channel]:\n",
    "                    self.channels[channel]['singles'] = {}\n",
    "                self.channels[channel]['singles'][trace_num] = {\n",
    "                    'data': df,\n",
    "                    'analysis': {}\n",
    "                }\n",
    "                if channel in files_per_channel:\n",
    "                    files_per_channel[channel] += 1\n",
    "                else:\n",
    "                    files_per_channel[channel] = 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "        total_files = sum(files_per_channel.values())\n",
    "        print(f\"Loaded {total_files} singles files across {len(files_per_channel)} channels for {self.name}\")\n",
    "        return files_per_channel\n",
    "    \n",
    "    def load_averages(self, path):\n",
    "        files = glob.glob(path)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found matching pattern: {path}\")\n",
    "            return {}\n",
    "        files_per_channel = {}\n",
    "        for file in files:\n",
    "            try:\n",
    "                filename = os.path.basename(file)\n",
    "                match = re.search(r'ch(\\d+)', filename)\n",
    "                if match:\n",
    "                    channel = int(match.group(1))\n",
    "                else:\n",
    "                    print(f\"Could not extract channel from {filename}, skipping\")\n",
    "                    continue\n",
    "                if channel in files_per_channel:\n",
    "                    trace_num = files_per_channel[channel]\n",
    "                else:\n",
    "                    trace_num = 0\n",
    "                df = pd.read_csv(file, skiprows=21, names=[\"time\", \"output\", \"input\", \"CH3\"])\n",
    "                for col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                df = df[[\"time\", \"output\", \"input\"]] if \"input\" in df.columns else df[[\"time\", \"output\"]]\n",
    "                if channel not in self.channels:\n",
    "                    self.channels[channel] = {}\n",
    "                if 'averages' not in self.channels[channel]:\n",
    "                    self.channels[channel]['averages'] = {}\n",
    "                self.channels[channel]['averages'][trace_num] = {\n",
    "                    'data': df,\n",
    "                    'analysis': {}\n",
    "                }\n",
    "                if channel in files_per_channel:\n",
    "                    files_per_channel[channel] += 1\n",
    "                else:\n",
    "                    files_per_channel[channel] = 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "        total_files = sum(files_per_channel.values())\n",
    "        print(f\"Loaded {total_files} averages files across {len(files_per_channel)} channels for {self.name}\")\n",
    "        return files_per_channel\n",
    "    \n",
    "    def load_data(self, singles_path=\"../data/casb1/singles/C1--Trace--*.txt\", averages_path=\"../data/casb1/averages/new/ch*.csv\"):\n",
    "        singles_result = {}\n",
    "        if singles_path:\n",
    "            singles_result = self.load_singles(singles_path)\n",
    "        averages_result = {}\n",
    "        if averages_path:\n",
    "            averages_result = self.load_averages(averages_path)\n",
    "        return len(singles_result), len(averages_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CASB2Processor(WaveformProcessor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"CASB2\")\n",
    "    \n",
    "    def load_singles(self, path):\n",
    "        files = glob.glob(path)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found matching pattern: {path}\")\n",
    "            return {}\n",
    "        files_per_channel = {}\n",
    "        for file in files:\n",
    "            try:\n",
    "                filename = os.path.basename(file)\n",
    "                ch_dir = os.path.basename(os.path.dirname(file))\n",
    "                ch_match = re.search(r'ch(\\d+)', ch_dir)\n",
    "                if ch_match:\n",
    "                    channel = int(ch_match.group(1))\n",
    "                else:\n",
    "                    ch_match = re.search(r'ch(\\d+)', filename)\n",
    "                    if ch_match:\n",
    "                        channel = int(ch_match.group(1))\n",
    "                    else:\n",
    "                        print(f\"Could not extract channel from {file}, skipping\")\n",
    "                        continue\n",
    "                trace_match = re.search(r'tek(\\d+)ALL', filename)\n",
    "                if trace_match:\n",
    "                    trace_num = int(trace_match.group(1))\n",
    "                else:\n",
    "                    if channel in files_per_channel:\n",
    "                        trace_num = files_per_channel[channel]\n",
    "                    else:\n",
    "                        trace_num = 0\n",
    "                \n",
    "                df = pd.read_csv(file, skiprows=21, names=[\"time\", \"output\", \"input\", \"CH3\"])\n",
    "                for col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                df = df[[\"time\", \"output\", \"input\"]] if \"input\" in df.columns else df[[\"time\", \"output\"]]\n",
    "                if channel not in self.channels:\n",
    "                    self.channels[channel] = {}\n",
    "                if 'singles' not in self.channels[channel]:\n",
    "                    self.channels[channel]['singles'] = {}\n",
    "                self.channels[channel]['singles'][trace_num] = {\n",
    "                    'data': df,\n",
    "                    'analysis': {}\n",
    "                }\n",
    "                if channel in files_per_channel:\n",
    "                    files_per_channel[channel] += 1\n",
    "                else:\n",
    "                    files_per_channel[channel] = 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "        \n",
    "        # Print summary\n",
    "        total_files = sum(files_per_channel.values())\n",
    "        print(f\"Loaded {total_files} singles files across {len(files_per_channel)} channels for {self.name}\")\n",
    "        \n",
    "        return files_per_channel\n",
    "    \n",
    "    def load_averages(self, path):\n",
    "        files = glob.glob(path)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found matching pattern: {path}\")\n",
    "            return {}\n",
    "            \n",
    "        files_per_channel = {}\n",
    "        \n",
    "        for file in files:\n",
    "            try:\n",
    "                filename = os.path.basename(file)\n",
    "                ch_match = re.search(r'tek(\\d+)ALL', filename)\n",
    "                if ch_match:\n",
    "                    channel = int(ch_match.group(1))\n",
    "                else:\n",
    "                    print(f\"Could not extract channel from {file}, skipping\")\n",
    "                    continue\n",
    "                if channel in files_per_channel:\n",
    "                    trace_num = files_per_channel[channel]\n",
    "                else:\n",
    "                    trace_num = 0\n",
    "                \n",
    "                df = pd.read_csv(file, skiprows=21, names=[\"time\", \"output\", \"input\", \"CH3\"])\n",
    "                for col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                df = df[[\"time\", \"output\", \"input\"]] if \"input\" in df.columns else df[[\"time\", \"output\"]]\n",
    "                \n",
    "                if channel not in self.channels:\n",
    "                    self.channels[channel] = {}\n",
    "                \n",
    "                if 'averages' not in self.channels[channel]:\n",
    "                    self.channels[channel]['averages'] = {}\n",
    "                \n",
    "                self.channels[channel]['averages'][trace_num] = {\n",
    "                    'data': df,\n",
    "                    'analysis': {}\n",
    "                }\n",
    "                \n",
    "                if channel in files_per_channel:\n",
    "                    files_per_channel[channel] += 1\n",
    "                else:\n",
    "                    files_per_channel[channel] = 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "        \n",
    "        # Print summary\n",
    "        total_files = sum(files_per_channel.values())\n",
    "        print(f\"Loaded {total_files} averages files across {len(files_per_channel)} channels for {self.name}\")\n",
    "        \n",
    "        return files_per_channel\n",
    "    \n",
    "    def load_data(self, singles_path=\"../data/casb2/singles/ch*/tek*ALL.csv\", averages_path=\"../data/casb2/averages/tek*ALL.csv\"):\n",
    "        singles_result = {}\n",
    "        if singles_path:\n",
    "            singles_result = self.load_singles(singles_path)\n",
    "        else:\n",
    "            singles_result = self.load_singles()  # Use default path\n",
    "        \n",
    "        averages_result = {}\n",
    "        if averages_path:\n",
    "            averages_result = self.load_averages(averages_path)\n",
    "        else:\n",
    "            averages_result = self.load_averages()  # Use default path\n",
    "        \n",
    "        return len(singles_result), len(averages_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTCAProcessor(WaveformProcessor):\n",
    "    \"\"\"Processor for MTCA board data.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"MTCA1\")\n",
    "    \n",
    "    def load_singles(self, path):\n",
    "        files = glob.glob(path)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found matching pattern: {path}\")\n",
    "            return {}\n",
    "            \n",
    "        files_per_channel = {}\n",
    "        \n",
    "        for file in files:\n",
    "            try:\n",
    "                filename = os.path.basename(file)\n",
    "                \n",
    "                # Extract channel and trace info\n",
    "                match = re.search(r'C(\\d+)--Trace--(\\d+)', filename)\n",
    "                if match:\n",
    "                    channel = int(match.group(1))\n",
    "                    trace_num = int(match.group(2))\n",
    "                else:\n",
    "                    match = re.search(r'Trace--(\\d+)', filename)\n",
    "                    if match:\n",
    "                        trace_num = int(match.group(1))\n",
    "                        channel = 4  # Default if not specified\n",
    "                    else:\n",
    "                        print(f\"Could not extract info from {filename}, skipping\")\n",
    "                        continue\n",
    "                \n",
    "                # Load data - adjust skiprows based on your file format\n",
    "                df = pd.read_csv(file, skiprows=6, names=[\"time\", \"output\"])\n",
    "                for col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                df['output'] = df['output'] * -1\n",
    "                # Initialize channel structure if needed\n",
    "                if channel not in self.channels:\n",
    "                    self.channels[channel] = {}\n",
    "                \n",
    "                # Initialize singles dict if needed\n",
    "                if 'singles' not in self.channels[channel]:\n",
    "                    self.channels[channel]['singles'] = {}\n",
    "                \n",
    "                # Store the trace\n",
    "                self.channels[channel]['singles'][trace_num] = {\n",
    "                    'data': df,\n",
    "                    'analysis': {}\n",
    "                } \n",
    "                \n",
    "                # Update counter\n",
    "                if channel in files_per_channel:\n",
    "                    files_per_channel[channel] += 1\n",
    "                else:\n",
    "                    files_per_channel[channel] = 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "                \n",
    "        # Print summary\n",
    "        total_files = sum(files_per_channel.values())\n",
    "        print(f\"Loaded {total_files} singles files across {len(files_per_channel)} channels for {self.name}\")\n",
    "        \n",
    "        return files_per_channel\n",
    "    \n",
    "    def load_averages(self, path):\n",
    "        files = glob.glob(path)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found matching pattern: {path}\")\n",
    "            return {}\n",
    "            \n",
    "        files_per_channel = {}\n",
    "        \n",
    "        for file in files:\n",
    "            try:\n",
    "                filename = os.path.basename(file)\n",
    "                match = re.search(r'ch(\\d+)', filename)\n",
    "                if match:\n",
    "                    channel = int(match.group(1))\n",
    "                else:\n",
    "                    print(f\"Could not extract channel from {filename}, skipping\")\n",
    "                    continue\n",
    "                \n",
    "                # Extract trace number if available, otherwise use counter\n",
    "                if channel in files_per_channel:\n",
    "                    trace_num = files_per_channel[channel]\n",
    "                else:\n",
    "                    trace_num = 0\n",
    "                \n",
    "                # Load data - adjust skiprows based on your file format\n",
    "                df = pd.read_csv(file, skiprows=6, names=[\"time\", \"output\"])\n",
    "                for col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "                # Initialize channel structure if needed\n",
    "                if channel not in self.channels:\n",
    "                    self.channels[channel] = {}\n",
    "                \n",
    "                # Initialize singles dict if needed\n",
    "                if 'averages' not in self.channels[channel]:\n",
    "                    self.channels[channel]['averages'] = {}\n",
    "                \n",
    "                # Store the trace\n",
    "                self.channels[channel]['averages'][trace_num] = {\n",
    "                    'data': df,\n",
    "                    'analysis': {}\n",
    "                } \n",
    "                \n",
    "                # Update counter\n",
    "                if channel in files_per_channel:\n",
    "                    files_per_channel[channel] += 1\n",
    "                else:\n",
    "                    files_per_channel[channel] = 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "                \n",
    "        # Print summary\n",
    "        total_files = sum(files_per_channel.values())\n",
    "        print(f\"Loaded {total_files} averages files across {len(files_per_channel)} channels for {self.name}\")\n",
    "        \n",
    "        return files_per_channel\n",
    "    \n",
    "    def load_data(self, singles_path=\"../data/mtca1/singles/C4--Trace--*.txt\", averages_path=\"Don't have MTCA averages yet\"):\n",
    "        singles_result = {}\n",
    "        if singles_path:\n",
    "            singles_result = self.load_singles(singles_path)\n",
    "        else:\n",
    "            singles_result = self.load_singles()  # Use default path\n",
    "        \n",
    "        averages_result = {}\n",
    "        if averages_path:\n",
    "            averages_result = self.load_averages(averages_path)\n",
    "        else:\n",
    "            try:\n",
    "                averages_result = self.load_averages()  # Use default path\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load averages with default path: {e}\")\n",
    "        \n",
    "        return len(singles_result), len(averages_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_combined_delays(boards, waveform_type='averages', trace_index=0, highlight_extremes=True):\n",
    "    \"\"\"\n",
    "    Create a combined bar plot showing delays from multiple boards.\n",
    "    \n",
    "    Args:\n",
    "        boards (list): List of WaveformProcessor instances\n",
    "        waveform_type (str): 'singles' or 'averages'\n",
    "        trace_index (int): Index of the trace to use\n",
    "        highlight_extremes (bool): Whether to highlight min/max delays\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The figure object\n",
    "    \"\"\"\n",
    "    # Make sure all boards have delay analysis\n",
    "    for board in boards:\n",
    "        channels_with_delays = 0\n",
    "        for ch in board.channels:\n",
    "            if ('analysis' in board.channels[ch] and \n",
    "                'delay' in board.channels[ch]['analysis']):\n",
    "                channels_with_delays += 1\n",
    "        \n",
    "        if channels_with_delays == 0:\n",
    "            print(f\"Calculating delays for {board.name} using {waveform_type}[{trace_index}]\")\n",
    "            try:\n",
    "                board.calculate_delays(waveform_type, trace_index)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not calculate delays for {board.name}: {e}\")\n",
    "    \n",
    "    # Get all channels across all boards\n",
    "    all_channels = set()\n",
    "    for board in boards:\n",
    "        all_channels.update(board.channels.keys())\n",
    "    all_channels = sorted(list(all_channels))\n",
    "    \n",
    "    # Create labels\n",
    "    labels = [f\"CH{ch}\" for ch in all_channels]\n",
    "    \n",
    "    # Set up the plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Calculate positions for bars\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.8 / len(boards)  # Width of the bars, adjusted for number of boards\n",
    "    \n",
    "    # Plot bars for each board\n",
    "    legend_items = []\n",
    "    \n",
    "    for i, board in enumerate(boards):\n",
    "        # Create dictionary mapping channel to delay\n",
    "        delay_dict = {}\n",
    "        for ch in board.channels:\n",
    "            if ('analysis' in board.channels[ch] and \n",
    "                'delay' in board.channels[ch]['analysis']):\n",
    "                delay_dict[ch] = board.channels[ch]['analysis']['delay']['value']\n",
    "        \n",
    "        # Fill in delays for all channels (use NaN for missing channels)\n",
    "        delays = [delay_dict.get(ch, np.nan) for ch in all_channels]\n",
    "        \n",
    "        # Calculate position adjustment\n",
    "        pos_adjustment = width * (i - (len(boards) - 1) / 2)\n",
    "        \n",
    "        # Create bars\n",
    "        bars = ax.bar(x + pos_adjustment, delays, width, label=board.name)\n",
    "        \n",
    "        if highlight_extremes:\n",
    "            # Find non-NaN values\n",
    "            valid_delays = [(idx, d) for idx, d in enumerate(delays) if not np.isnan(d)]\n",
    "            if valid_delays:\n",
    "                valid_indices, valid_values = zip(*valid_delays)\n",
    "                \n",
    "                # Find min (excluding 0 which might be reference)\n",
    "                non_zero_values = [d for d in valid_values if d != 0]\n",
    "                if non_zero_values:\n",
    "                    min_val = min(non_zero_values)\n",
    "                    min_idx = valid_indices[valid_values.index(min_val)]\n",
    "                    max_val = max(valid_values)\n",
    "                    max_idx = valid_indices[valid_values.index(max_val)]\n",
    "                    \n",
    "                    # Highlight min/max bars\n",
    "                    bars[min_idx].set_color('lightgreen')\n",
    "                    bars[max_idx].set_color('tomato')\n",
    "                    \n",
    "                    # Add value labels\n",
    "                    ax.text(x[min_idx] + pos_adjustment, delays[min_idx]+20, \n",
    "                           f\"{delays[min_idx]:.0f}\", ha='center', rotation=90, fontsize=8)\n",
    "                    ax.text(x[max_idx] + pos_adjustment, delays[max_idx]+20, \n",
    "                           f\"{delays[max_idx]:.0f}\", ha='center', rotation=90, fontsize=8)\n",
    "        \n",
    "        # Calculate standard deviation for legend\n",
    "        valid_delays = [d for d in delays if not np.isnan(d) and d != 0]\n",
    "        std_dev = np.std(valid_delays) if valid_delays else 0\n",
    "        legend_items.append(f'{board.name} ($\\\\sigma= {std_dev:.2f}$)')\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_xlabel(\"Channel\")\n",
    "    ax.set_ylabel(\"Delay Relative to Reference Channel [ps]\")\n",
    "    ax.set_title(f\"Unity Path Relative Channel Delays Comparison ({waveform_type})\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=90)\n",
    "    \n",
    "    # Find appropriate y-limit - skip NaN and inf values\n",
    "    all_delays = []\n",
    "    for board in boards:\n",
    "        for ch in board.channels:\n",
    "            if ('analysis' in board.channels[ch] and \n",
    "                'delay' in board.channels[ch]['analysis']):\n",
    "                value = board.channels[ch]['analysis']['delay']['value']\n",
    "                if not np.isnan(value) and not np.isinf(value):\n",
    "                    all_delays.append(value)\n",
    "    \n",
    "    if all_delays:\n",
    "        max_delay = max(all_delays)\n",
    "        ax.set_ylim(0, max_delay * 1.2)  # Add 20% margin\n",
    "    \n",
    "    # Add legend with standard deviations\n",
    "    ax.legend(legend_items)\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_board_rise_times(boards, waveform_type):\n",
    "    board_rise_times = {}\n",
    "    for board in boards:\n",
    "        rise_times = []\n",
    "        for channel in board.channels:\n",
    "            if waveform_type in board.channels[channel]:\n",
    "                for trace_num in board.channels[channel][waveform_type]:\n",
    "                    analysis = board.channels[channel][waveform_type][trace_num]['analysis']\n",
    "                    rise_times.append(analysis['output_rise_time'])\n",
    "        board_rise_times[board.name] = rise_times\n",
    "    # Determine shared bins\n",
    "    all_data = []\n",
    "    for board in board_rise_times:\n",
    "        for rise_time in board_rise_times[board]:   \n",
    "            all_data.append(rise_time)\n",
    "    bins = np.arange(np.floor(min(all_data)*4)/4, np.ceil(max(all_data)*4)/4, 0.25)\n",
    "    for board in board_rise_times:\n",
    "        plt.hist(board_rise_times[board], bins=bins, density=True, histtype='step',label=board)\n",
    "    plt.xlabel('Rise Time [ps]')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Comparason of Different Summing Boards Rise Times')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_pct = 0.3\n",
    "high_pct = 0.7\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 singles files across 1 channels for CASB1\n",
      "Loaded 20 averages files across 20 channels for CASB1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "casb1 = CASB1Processor();\n",
    "casb1.load_data();\n",
    "casb1.calculate_all_rise_times(waveform_type='singles', baseline_start_pct=0.6, baseline_end_pct=1, threshold=8, low_pct=low_pct, high_pct=high_pct,output=True,input=False);\n",
    "#casb1.plot_waveform(channel=1, waveform_type='singles', trace_index=0, show_rise_time_analysis=True,output=True,input=False);\n",
    "#casb1.plot_all_waveforms(waveform_type='singles', show_rise_time_analysis=True,output=True,input=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400 singles files across 20 channels for CASB2\n",
      "Loaded 20 averages files across 20 channels for CASB2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "casb2 = CASB2Processor();\n",
    "casb2.load_data();\n",
    "casb2.calculate_all_rise_times(waveform_type='singles', baseline_start_pct=0, baseline_end_pct=0.4, threshold=8, low_pct=low_pct, high_pct=high_pct,output=True,input=False);\n",
    "casb2.calculate_all_rise_times(waveform_type='singles', baseline_start_pct=0.8, baseline_end_pct=1, threshold=10, low_pct=low_pct, high_pct=high_pct,output=False,input=True);\n",
    "#casb2.plot_waveform(channel=6, waveform_type='singles', trace_index=5, show_rise_time_analysis=True,output=True,input=True);\n",
    "#casb2.plot_all_waveforms(waveform_type='singles', show_rise_time_analysis=True);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 35 singles files across 1 channels for MTCA1\n",
      "Warning: No files found matching pattern: Don't have MTCA averages yet\n"
     ]
    }
   ],
   "source": [
    "mtca1 = MTCAProcessor();\n",
    "mtca1.load_data();\n",
    "mtca1.calculate_all_rise_times(waveform_type='singles',baseline_start_pct=0,baseline_end_pct=0.2,threshold=10,low_pct=low_pct,high_pct=high_pct,output=True,input=False);\n",
    "\n",
    "#mtca1.plot_waveform(channel=4,waveform_type='singles',trace_index=0,show_rise_time_analysis=True,output=True,input=False);\n",
    "#mtca1.plot_all_waveforms(waveform_type='singles',show_rise_time_analysis=True,output=True,input=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histogram_board_rise_times([casb1, casb2, mtca1], waveform_type='singles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#mtca1.calculate_all_rise_times()\n",
    "\n",
    "# # Calculate delays using averages data\n",
    "# casb1.calculate_delays(waveform_type='averages', trace_index=0)\n",
    "# casb2.calculate_delays(waveform_type='averages', trace_index=0)\n",
    "# mtca.calculate_delays(waveform_type='averages', trace_index=0)\n",
    "\n",
    "# # Calculate gains using averages data\n",
    "# casb1.calculate_gains(waveform_type='averages', trace_index=0)\n",
    "# casb2.calculate_gains(waveform_type='averages', trace_index=0)\n",
    "# mtca.calculate_gains(waveform_type='averages', trace_index=0)\n",
    "\n",
    "# # Plot a sample waveform\n",
    "#casb2.plot_all_waveforms(waveform_type='singles', show_rise_time_analysis=True);\n",
    "#mtca1.plot_all_waveforms(waveform_type='singles', show_rise_time_analysis=True);_\n",
    "\n",
    "# # Plot delays for individual boards\n",
    "# casb1.plot_delays(highlight_extremes=True)\n",
    "# casb2.plot_delays(highlight_extremes=True)\n",
    "\n",
    "# # Plot combined delays\n",
    "# plot_combined_delays([casb1, casb2, mtca], waveform_type='averages', trace_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
